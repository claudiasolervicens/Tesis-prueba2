{
    "collab_server" : "",
    "contents" : "pacman::p_load(NLP,tm,SnowballC,readxl,wordcloud,RColorBrewer,dplyr)\n\n\npath<-\"Data.xlsx\"\nxlsx_excel<-read_excel(path)\nexcel_sheets(path)\nDataMaestra<-read_excel(path, sheet = \"Hoja4\")\n\nView(DataMaestra)\n\nTest<-filter(DataMaestra,Test==1);View(Test)\nDataMaestra<-filter(DataMaestra,Test==0);View(DataMaestra)\n\n\n#cargar el corpus de documentos\n#DataMaestra=as.data.frame(read.csv2(\"C:/Users/Claudia/OneDrive/Documents/Publicaciones/AbstractsFinales.csv\"))\n\n################################ funciones #########################################################################\n\n#Recibe un vector de character y entrega la lista de los más frecuentes ordenada.\nDoc_term_Matrix<-function (StringVector)\n{\n  StringVector<-Corpus(VectorSource(StringVector))\n  \n  toSpace <- content_transformer(function(x, pattern) { return (gsub(pattern, \" \", x))})\n  \n  vector_cleaning<-c(\"!\",\"#\",\"$\",\"%\",\"&\",\"/\", \"•\", \"‘\", \"’\", \"-\",\"<\", \">\")\n  \n  for (i in 1:length(vector_cleaning))\n  {\n    StringVector <- tm_map(StringVector, toSpace, vector_cleaning[i])\n  }\n  \n  \n  #remover signos de  puntuación\n  StringVector <- tm_map(StringVector, removePunctuation)\n  \n  #remover número\n  StringVector <- tm_map(StringVector, removeNumbers)\n  \n  StringVector <-tm_map(StringVector,content_transformer(tolower))\n  \n  #cargar la lista de stopwords\n  stopwords <- c(stopwords(kind = \"english\"))\n  \n  #remover stopwords\n  StringVector <- tm_map(StringVector, removeWords, stopwords)\n  \n  #remover whitespace\n  StringVector <- tm_map(StringVector, stripWhitespace)\n  \n  #cargar la lista de generic terms\n  genericterms <- readLines(\"genericterms.txt\")\n  \n  #remover generic terms\n  StringVector <- tm_map(StringVector, removeWords, genericterms)\n  \n  #aplicar stemming al documento\n  StringVector <- tm_map(StringVector,stemDocument, language =\"english\")\n  \n  #remover generic terms\n  StringVector <- tm_map(StringVector, removeWords, genericterms)\n  \n  dtm <- DocumentTermMatrix(StringVector)\n  \n  dtm\n}\n\n\n\n\nKeyword<-function (StringVector)\n{\n  StringVector<-Corpus(VectorSource(StringVector))\n  \n  toSpace <- content_transformer(function(x, pattern) { return (gsub(pattern, \" \", x))})\n\n  vector_cleaning<-c(\"!\",\"#\",\"$\",\"%\",\"&\",\"/\", \"•\", \"‘\", \"’\", \"-\",\"<\", \">\")\n  \n  for (i in 1:length(vector_cleaning))\n  {\n    StringVector <- tm_map(StringVector, toSpace, vector_cleaning[i])\n  }\n\n\n  #remover signos de  puntuación\n  StringVector <- tm_map(StringVector, removePunctuation)\n  \n  #remover número\n  StringVector <- tm_map(StringVector, removeNumbers)\n\n  StringVector <-tm_map(StringVector,content_transformer(tolower))\n  \n  #cargar la lista de stopwords\n  stopwords <- c(stopwords(kind = \"english\"))\n  \n  #remover stopwords\n  StringVector <- tm_map(StringVector, removeWords, stopwords)\n  \n  #remover whitespace\n  StringVector <- tm_map(StringVector, stripWhitespace)\n  \n  #cargar la lista de generic terms\n  genericterms <- readLines(\"genericterms.txt\")\n  \n  #remover generic terms\n  StringVector <- tm_map(StringVector, removeWords, genericterms)\n    \n  #aplicar stemming al documento\n  StringVector <- tm_map(StringVector,stemDocument, language =\"english\")\n  \n  #remover generic terms\n  StringVector <- tm_map(StringVector, removeWords, genericterms)\n\n  dtm <- DocumentTermMatrix(StringVector)\n  \n  #agrupar sumando por columnas\n  freq <- colSums(as.matrix(dtm))\n  \n  #el largo debe ser igual a total de términos\n  length(freq)-ncol(dtm)==0\n  \n  #ordenar por frecuencia (descendiente)\n  ord <- order(freq,decreasing=TRUE)\n  \n  #Enlistar los términos por frecuencia\n  data.frame(freq[ord])\n  \n}\n\n\nKeyword_rev<-function(StringVector)\n{\n  StringVector<-Corpus(VectorSource(StringVector))\n  \n  toSpace <- content_transformer(function(x, pattern) { return (gsub(pattern, \" \", x))})\n  \n  vector_cleaning<-c(\"!\",\"#\",\"$\",\"%\",\"&\",\"/\", \"•\", \"‘\", \"’\", \"-\",\"<\", \">\")\n  \n  for (i in 1:length(vector_cleaning))\n  {\n    StringVector <- tm_map(StringVector, toSpace, vector_cleaning[i])\n  }\n  \n  \n  #cargar la lista de generic terms\n  genericterms_rev <- readLines(\"genericterms_revista.txt\")\n  \n  #remover generic terms\n  StringVector <- tm_map(StringVector, removeWords, genericterms_rev)\n  \n  #remover signos de  puntuación\n  StringVector <- tm_map(StringVector, removePunctuation)\n  \n  #remover número\n  StringVector <- tm_map(StringVector, removeNumbers)\n  \n  StringVector <-tm_map(StringVector,content_transformer(tolower))\n  \n  #cargar la lista de stopwords\n  stopwords <- c(stopwords(kind = \"english\"))\n  \n  #remover stopwords\n  StringVector <- tm_map(StringVector, removeWords, stopwords)\n  \n  #remover whitespace\n  StringVector <- tm_map(StringVector, stripWhitespace)\n  \n\n  \n\n  #aplicar stemming al documento\n  StringVector <- tm_map(StringVector,stemDocument, language =\"english\")\n  \n  \n  #remover generic terms\n  StringVector <- tm_map(StringVector, removeWords, genericterms_rev)\n  \n  \n  dtm <- DocumentTermMatrix(StringVector)\n  \n  #agrupar sumando por columnas\n  freq <- colSums(as.matrix(dtm))\n  \n  #el largo debe ser igual a total de términos\n  length(freq)-ncol(dtm)==0\n  \n  #ordenar por frecuencia (descendiente)\n  ord <- order(freq,decreasing=TRUE)\n  \n  #Enlistar los términos por frecuencia\n  data.frame(freq[ord])\n  \n}\n\n\n\n#Busca dentro de un texto una palabra y retorna TRUE si es que existe.\nexiste_palabra<-function(abstract,p_encontrada)\n{\n  existe=FALSE\n  abs2<-unlist(strsplit(abstract,\" \"))\n  if(is.element(p_encontrada,abs2))\n  {\n    existe=TRUE\n  }\n  return(existe)\n}\n\n#######################  Metadata de la respuesta ##################################################################\n\n#Se inicializa la primera palabra\npalabra_encontrada=\"\"\n\n#Se inicializan las categorías con las palabras claves del texto. Se le añade la frecuencia, categoría, y la iteración.\nDataMaestra=mutate(DataMaestra,key1=\"\",key2=\"\",key3=\"\",key4=\"\",key5=\"\",\n                   Categoria_1=\"\",Frecuencia_1=0,j_1=0,Porcentaje=0.0\n)\n\n\n#Todavía no ha terminado, y la iteración es cero\nTerminar=FALSE\nj=0\n\nAux<-DataMaestra\n\n#Todo el corpus como un vector\nAbstractVector=as.vector(Aux$Abstract)\n\n#Vector vacío\nTotalKeyWords=vector(mode = \"character\",length=length(AbstractVector))\n\n######################################## Palabras Frecuentes        #########################################\n\n\nfor(i in 1:nrow(DataMaestra)){\n  \n  #Cada abstract como un vector\n  NewAbstractVector=as.character(DataMaestra[i,\"Abstract\"])\n  \n  KeyWordsAbsi=Keyword(NewAbstractVector)\n  rownamesFreq=rownames(KeyWordsAbsi)\n  DataMaestra[i,\"key1\"]=rownamesFreq[1]\n  DataMaestra[i,\"key2\"]=rownamesFreq[2]\n  DataMaestra[i,\"key3\"]=rownamesFreq[3]\n  DataMaestra[i,\"key4\"]=rownamesFreq[4]\n  DataMaestra[i,\"key5\"]=rownamesFreq[5]\n}\n\nView(DataMaestra)\n\n############################################################################################################\nAux<-DataMaestra\n\n\n\nwhile(!Terminar)\n{\n    \n      #El conjunto de las palabras más frecuentes de cada abstract <-- \n      #Aquí la diferencia de haber sacado las más frecuentes del conjunto completo, \n      #esto es más representativo de lo que es importante en cada uno\n      prop<-1\n      TotalKeyWords=paste(Aux[,\"key1\"],Aux[,\"key2\"],Aux[,\"key3\"],Aux[,\"key4\"],Aux[,\"key5\"],sep=\" \")\n      TotalKeyWordsC<-Corpus(VectorSource(TotalKeyWords))\n      TotalKeyWordsC <-tm_map(TotalKeyWordsC,content_transformer(tolower))\n      toSpace <- content_transformer(function(x, pattern) { return (gsub(pattern, \" \", x))})\n      dtm <- DocumentTermMatrix(TotalKeyWordsC)\n      \n      #agrupar sumando por columnas\n      freq <- colSums(as.matrix(dtm))\n      \n      #el largo debe ser igual a total de términos\n      length(freq)-ncol(dtm)==0\n      \n      #ordenar por frecuencia (descendiente)\n      ord <- order(freq,decreasing=TRUE)\n      \n      #Enlistar los términos por frecuencia\n      FrecuenciaFinal=data.frame(freq[ord])\n            \n      palabra_encontrada=rownames(FrecuenciaFinal)[1]\n\n      \n      #Colocar la etiqueta de categoria\n      for(i in 1:nrow(DataMaestra))\n      {\n        if(existe_palabra(paste(DataMaestra[i,\"key1\"],DataMaestra[i,\"key2\"],DataMaestra[i,\"key3\"],DataMaestra[i,\"key4\"],DataMaestra[i,\"key5\"],sep=\" \"),palabra_encontrada) && DataMaestra[i,\"Categoria_1\"]==\"\")\n        {\n          DataMaestra[i,\"Categoria_1\"]=palabra_encontrada\n          DataMaestra[i,\"Frecuencia_1\"]=FrecuenciaFinal[1,1]\n          DataMaestra[i,\"j_1\"]=j\n          DataMaestra[i,\"Porcentaje\"]=FrecuenciaFinal[1,1]/nrow(DataMaestra)\n          prop<-FrecuenciaFinal[1,1]/nrow(DataMaestra)\n        }\n      }\n\n      print(j)\n      print(prop)\n      print(palabra_encontrada)\n      j=j+1\n      Aux<-filter(DataMaestra,Categoria_1==\"\")\n      print(nrow(Aux))\n      if(nrow(Aux)==0 || prop<0.01)\n      {\n        Terminar=TRUE\n      }\n      \n}\n\n\n# NivelesCategorias<-levels(as.factor(DataMaestra$Categoria_1))\n# for (i in 1:length(NivelesCategorias))\n# {\n#   #DataMaestra[,NivelesCategorias[i]]\n#   Words<-filter(DataMaestra,Categoria_1==NivelesCategorias[i]) \n#   print(i)\n#   FrecuenciaFinal<-Keyword(Words$Abstract)\n#   archivo<-paste(NivelesCategorias[i],\"_wordcloud_11_9.png\")\n#   png(filename=archivo)\n#   layout(matrix(c(1, 2), nrow=2), heights=c(1, 4))\n#   par(mar=rep(0, 4))\n#   plot.new()\n#   text(x=0.5, y=0.5, paste(NivelesCategorias[i],\" Wordcloud\"))\n#   \n#   wordcloud(words = rownames(FrecuenciaFinal)[2:length(rownames(FrecuenciaFinal))], freq = FrecuenciaFinal$freq.ord.[2:length(FrecuenciaFinal$freq.ord.)], min.freq = 1,\n#             max.words=200, random.order=FALSE, rot.per=0.35, \n#             colors=brewer.pal(8, \"Dark2\"),main=\"Title\")\n#   dev.off()\n# }\n\n\n\n###################  K-Means ##########################################\n\n\n\n####Document Term Matrix Sobre el Corpus\nNewAbstractVector=unlist(as.vector(DataMaestra[,\"Abstract\"]))\nmat<-Doc_term_Matrix(NewAbstractVector);mat\n\n \n#Term Frequency Inverse Term\nmat4 <- weightTfIdf(mat)\nmat4 <- as.matrix(mat4)\n\n#Normalizar los Scores por distancia Euclidiana\nnorm_eucl <- function(m)\n  m/apply(m,1,function(x) sum(x^2)^.5)\nmat_norm <- norm_eucl(mat4)\n\n\nset.seed(5)\nk <- 30\nkmeansResult <- kmeans(mat_norm, k)\nDataMaestra$Cluster_15<-kmeansResult$cluster\nView(DataMaestra)\n\n#NivelesCategorias<-levels(as.factor(DataMaestra$Cluster_3))\n\n# for (i in 1:length(NivelesCategorias))\n# {\n#   #DataMaestra[,NivelesCategorias[i]]\n#   Words<-filter(DataMaestra,Cluster_3==NivelesCategorias[i]) \n#   print(i)\n#   FrecuenciaFinal<-Keyword(Words$Abstract)\n#   archivo<-paste(NivelesCategorias[i],\"_wordcloud_Cluster_k3.png\")\n#   png(filename=archivo)\n#   layout(matrix(c(1, 2), nrow=2), heights=c(1, 4))\n#   par(mar=rep(0, 4))\n#   plot.new()\n#   text(x=0.5, y=0.5, paste(NivelesCategorias[i],\" Wordcloud\"))\n#   \n#   wordcloud(words = rownames(FrecuenciaFinal), freq = FrecuenciaFinal$freq.ord., min.freq = 1,\n#             max.words=200, random.order=FALSE, rot.per=0.35, \n#             colors=brewer.pal(8, \"Dark2\"),main=\"Title\")\n#   dev.off()\n# }\n\n\n\nset.seed(5)\nk <- 40\nkmeansResult <- kmeans(mat_norm, k)\nDataMaestra$Cluster_8<-kmeansResult$cluster\nView(DataMaestra)\n\n#NivelesCategorias<-levels(as.factor(DataMaestra$Cluster_8))\n\n# for (i in 1:length(NivelesCategorias))\n# {\n#   #DataMaestra[,NivelesCategorias[i]]\n#   Words<-filter(DataMaestra,Cluster_8==NivelesCategorias[i]) \n#   print(i)\n#   FrecuenciaFinal<-Keyword(Words$Abstract)\n#   archivo<-paste(NivelesCategorias[i],\"_wordcloud_Cluster_k8.png\")\n#   png(filename=archivo)\n#   layout(matrix(c(1, 2), nrow=2), heights=c(1, 4))\n#   par(mar=rep(0, 4))\n#   plot.new()\n#   text(x=0.5, y=0.5, paste(NivelesCategorias[i],\" Wordcloud\"))\n#   \n#   wordcloud(words = rownames(FrecuenciaFinal), freq = FrecuenciaFinal$freq.ord., min.freq = 1,\n#             max.words=200, random.order=FALSE, rot.per=0.35, \n#             colors=brewer.pal(8, \"Dark2\"),main=\"Title\")\n#   dev.off()\n# }\n\nset.seed(5)\nk <- 50\nkmeansResult <- kmeans(mat_norm, k)\nsaveRDS(kmeansResult,\"kmeans.rds\")\nDataMaestra$Cluster_20<-kmeansResult$cluster\nView(DataMaestra)\n\n\n# NivelesCategorias<-levels(as.factor(DataMaestra$Cluster_10))\n# \n# \n# for (i in 1:length(NivelesCategorias))\n# {\n#   #DataMaestra[,NivelesCategorias[i]]\n#   Words<-filter(DataMaestra,Cluster_10==NivelesCategorias[i]) \n#   print(i)\n#   FrecuenciaFinal<-Keyword(Words$Abstract)\n#   archivo<-paste(NivelesCategorias[i],\"_wordcloud_Cluster_k10.png\")\n#   png(filename=archivo)\n#   layout(matrix(c(1, 2), nrow=2), heights=c(1, 4))\n#   par(mar=rep(0, 4))\n#   plot.new()\n#   text(x=0.5, y=0.5, paste(NivelesCategorias[i],\" Wordcloud\"))\n#   \n#   wordcloud(words = rownames(FrecuenciaFinal), freq = FrecuenciaFinal$freq.ord., min.freq = 1,\n#             max.words=200, random.order=FALSE, rot.per=0.35, \n#             colors=brewer.pal(8, \"Dark2\"),main=\"Title\")\n#   dev.off()\n# }\n\n\n####################### LDA #############################################\nlibrary(topicmodels)\nk <- 35\nlda <- LDA(mat, k)\nterms(lda)\n\nsaveRDS(lda,\"lda.rds\")\n\nDataMaestra$lda_10<-topics(lda)\n\n#Exportar resultados\n#docs en cada tópico\nlda.topicos <- as.matrix(topics(lda))\nwrite.csv(lda.topicos,file=paste(\"C:/Users/Claudia/Documents/Tesis/LDA\",k,\"DocsTopicos.csv\"))\n\n#palabras con mayor frecuencia en cada tópico\nlda.palabras <- as.matrix(terms(lda, 10))\nwrite.csv(lda.palabras,file=paste(\"C:/Users/Claudia/Documents/Tesis/LDA\",k,\"TopicosPalabras.csv\"))\n\n\n#probabilidad de que cada documento esté asociado a cada topico \nProbDocTopico <- as.data.frame(lda@gamma)\nwrite.csv(ProbDocTopico,file=paste(\"C:/Users/Claudia/Documents/Tesis/LDA\",k,\"ProbTopico.csv\"))\n\n#probabilidad de cada palabra esté asociada a un tópico\nProbPalabraTopico <- as.data.frame(exp(lda@beta))\nwrite.csv(ProbPalabraTopico,file=paste(\"C:/Users/Claudia/Documents/Tesis/LDA\",k,\"ProbPalabraTopico.csv\"))\n\nlibrary(topicmodels)\nk <- 40\nlda <- LDA(mat, k)\nterms(lda)\n\nsaveRDS(lda,\"lda.rds\")\n\nDataMaestra$lda_10<-topics(lda)\n\n#Exportar resultados\n#docs en cada tópico\nlda.topicos <- as.matrix(topics(lda))\nwrite.csv(lda.topicos,file=paste(\"C:/Users/Claudia/Documents/Tesis/LDA\",k,\"DocsTopicos.csv\"))\n\n#palabras con mayor frecuencia en cada tópico\nlda.palabras <- as.matrix(terms(lda, 10))\nwrite.csv(lda.palabras,file=paste(\"C:/Users/Claudia/Documents/Tesis/LDA\",k,\"TopicosPalabras.csv\"))\n\n\n#probabilidad de que cada documento esté asociado a cada topico \nProbDocTopico <- as.data.frame(lda@gamma)\nwrite.csv(ProbDocTopico,file=paste(\"C:/Users/Claudia/Documents/Tesis/LDA\",k,\"ProbTopico.csv\"))\n\n#probabilidad de cada palabra esté asociada a un tópico\nwrite.csv(ProbPalabraTopico,file=paste(\"C:/Users/Claudia/Documents/Tesis/LDA\",k,\"ProbPalabraTopico.csv\"))P\nrobPalabraTopico <- as.data.frame(exp(lda@beta))\n\nlibrary(topicmodels)\nk <- 20\nlda <- LDA(mat, k)\nterms(lda)\n\nsaveRDS(lda,\"lda.rds\")\n\nDataMaestra$lda_10<-topics(lda)\n\n#Exportar resultados\n#docs en cada tópico\nlda.topicos <- as.matrix(topics(lda))\nwrite.csv(lda.topicos,file=paste(\"C:/Users/Claudia/Documents/Tesis/LDA\",k,\"DocsTopicos.csv\"))\n\n#palabras con mayor frecuencia en cada tópico\nlda.palabras <- as.matrix(terms(lda, 10))\nwrite.csv(lda.palabras,file=paste(\"C:/Users/Claudia/Documents/Tesis/LDA\",k,\"TopicosPalabras.csv\"))\n\n\n#probabilidad de que cada documento esté asociado a cada topico \nProbDocTopico <- as.data.frame(lda@gamma)\nwrite.csv(ProbDocTopico,file=paste(\"C:/Users/Claudia/Documents/Tesis/LDA\",k,\"ProbTopico.csv\"))\n\n#probabilidad de cada palabra esté asociada a un tópico\nProbPalabraTopico <- as.data.frame(exp(lda@beta))\nwrite.csv(ProbPalabraTopico,file=paste(\"C:/Users/Claudia/Documents/Tesis/LDA\",k,\"ProbPalabraTopico.csv\"))\n\n\n\n\n\n\nlibrary(topicmodels)\nk <- 50\nlda <- LDA(mat, k)\nterms(lda)\n\nsaveRDS(lda,\"lda.rds\")\n\nDataMaestra$lda_10<-topics(lda)\n\n# NivelesCategorias<-levels(as.factor(DataMaestra$lda_10))\n# \n# for (i in 1:length(NivelesCategorias))\n# {\n#   #DataMaestra[,NivelesCategorias[i]]\n#   Words<-filter(DataMaestra,lda_10==NivelesCategorias[i]) \n#   print(i)\n#   FrecuenciaFinal<-Keyword(Words$Abstract)\n#   archivo<-paste(NivelesCategorias[i],\"_wordcloud_lda_10.png\")\n#   png(filename=archivo)\n#   layout(matrix(c(1, 2), nrow=2), heights=c(1, 4))\n#   par(mar=rep(0, 4))\n#   plot.new()\n#   text(x=0.5, y=0.5, paste(NivelesCategorias[i],\" Wordcloud\"))\n#   \n#   wordcloud(words = rownames(FrecuenciaFinal), freq = FrecuenciaFinal$freq.ord., min.freq = 1,\n#             max.words=200, random.order=FALSE, rot.per=0.35, \n#             colors=brewer.pal(8, \"Dark2\"),main=\"Title\")\n#   dev.off()\n# }\n\n#Exportar resultados\n#docs en cada tópico\nlda.topicos <- as.matrix(topics(lda))\nwrite.csv(lda.topicos,file=paste(\"C:/Users/Claudia/Documents/Tesis/LDA\",k,\"DocsTopicos.csv\"))\n\n#palabras con mayor frecuencia en cada tópico\nlda.palabras <- as.matrix(terms(lda, 10))\nwrite.csv(lda.palabras,file=paste(\"C:/Users/Claudia/Documents/Tesis/LDA\",k,\"TopicosPalabras.csv\"))\n\n\n#probabilidad de que cada documento esté asociado a cada topico \nProbDocTopico <- as.data.frame(lda@gamma)\nwrite.csv(ProbDocTopico,file=paste(\"C:/Users/Claudia/Documents/Tesis/LDA\",k,\"ProbTopico.csv\"))\n\n#probabilidad de cada palabra esté asociada a un tópico\nProbPalabraTopico <- as.data.frame(exp(lda@beta))\n\nlibrary(topicmodels)\nk <- 55\nlda <- LDA(mat, k)\nterms(lda)\n\nsaveRDS(lda,\"lda30.rds\")\n\nDataMaestra$lda_30<-topics(lda)\n\nsaveRDS(DataMaestra,\"DataFinal.rds\")\n\n#Exportar resultados\n#docs en cada tópico\nlda.topicos <- as.matrix(topics(lda))\nwrite.csv(lda.topicos,file=paste(\"C:/Users/Claudia/Documents/Tesis/LDA\",k,\"DocsTopicos.csv\"))\n\n#palabras con mayor frecuencia en cada tópico\nlda.palabras <- as.matrix(terms(lda, 10))\nwrite.csv(lda.palabras,file=paste(\"C:/Users/Claudia/Documents/Tesis/LDA\",k,\"TopicosPalabras.csv\"))\n\n\n#probabilidad de que cada documento esté asociado a cada topico \nProbDocTopico <- as.data.frame(lda@gamma)\nwrite.csv(ProbDocTopico,file=paste(\"C:/Users/Claudia/Documents/Tesis/LDA\",k,\"ProbTopico.csv\"))\n\n#probabilidad de cada palabra esté asociada a un tópico\nProbPalabraTopico <- as.data.frame(exp(lda@beta))\n\nlibrary(topicmodels)\nk <- 48\nlda <- LDA(mat, k)\nterms(lda)\n\nsaveRDS(lda,\"lda45.rds\")\n\nDataMaestra$lda_45<-topics(lda)\n\nsaveRDS(DataMaestra,\"DataFinal.rds\")\n\n\nTesteoRDS<-readRDS(\"DataFinal.rds\")\n\nDataMaestra<-readRDS(\"DataFinal.rds\")\n\n#Exportar resultados\n#docs en cada tópico\nlda.topicos <- as.matrix(topics(lda))\nwrite.csv(lda.topicos,file=paste(\"C:/Users/Claudia/Documents/Tesis/LDA\",k,\"DocsTopicos.csv\"))\n\n#palabras con mayor frecuencia en cada tópico\nlda.palabras <- as.matrix(terms(lda, 10))\nwrite.csv(lda.palabras,file=paste(\"C:/Users/Claudia/Documents/Tesis/LDA\",k,\"TopicosPalabras.csv\"))\n\n\n#probabilidad de que cada documento esté asociado a cada topico \nProbDocTopico <- as.data.frame(lda@gamma)\nwrite.csv(ProbDocTopico,file=paste(\"C:/Users/Claudia/Documents/Tesis/LDA\",k,\"ProbTopico.csv\"))\n\n#probabilidad de cada palabra esté asociada a un tópico\nProbPalabraTopico <- as.data.frame(exp(lda@beta))\n######################## Evaluación  Modelos no Supervisados ###########################################\n26/11/17 17:36 creo que funcionó hasta aquí\n\nView(as.data.frame(table(DataMaestra$Disciplina,DataMaestra$lda_30)))\n#install.packages(\"reshape\")\nlibrary(reshape)\n\nas.data.frame(table(DataMaestra$Disciplina,DataMaestra$lda_30))%>%cast(Var1~Var2)->tablaResultadosLDA30;tablaResultadosLDA30%>%View()\n\n\ntablaResultadosLDA30%>%select(2:31)%>%rowSums()->TotalCat\ntablaResultadosLDA30%>%select(2:31)/as.vector(TotalCat)->Porcentaje\n\ncbind(tablaResultadosLDA30[,1],Porcentaje)->df\ndf[df == 0] <- NA\nView(df)\ndf%>%as.data.frame()%>%write.csv2(\"DATOS.csv\")\n\n####Ver como exportar\n\n#########################################################################\n#################### Aprendizaje Supervisado ############################\n#########################################################################\n\nlibrary(caTools)\n\nstratified = function(df, group, size) {\n  #  USE: * Specify your data frame and grouping variable (as column \n  #         number) as the first two arguments.\n  #       * Decide on your sample size. For a sample proportional to the\n  #         population, enter \"size\" as a decimal. For an equal number \n  #         of samples from each group, enter \"size\" as a whole number.\n  #\n  #  Example 1: Sample 10% of each group from a data frame named \"z\",\n  #             where the grouping variable is the fourth variable, use:\n  # \n  #                 > stratified(z, 4, .1)\n  #\n  #  Example 2: Sample 5 observations from each group from a data frame\n  #             named \"z\"; grouping variable is the third variable:\n  #\n  #                 > stratified(z, 3, 5)\n  #\n  require(sampling)\n  temp = df[order(df[group]),]\n  if (size < 1) {\n    size = ceiling(table(temp[group]) * size)\n  } else if (size >= 1) {\n    size = rep(size, times=length(table(temp[group])))\n  }  \n  strat = strata(temp, stratanames = names(temp[group]), \n                 size = size, method = \"srswor\")\n  (dsample = getdata(temp, strat))\n}\n\n########################################################################\n############################## Tratamiento de Revistas #################\n########################################################################\n\n#Keyword_rev(DataMaestra$Titulo_Revista)%>%View()\n\n\n#######################  Metadata de la respuesta ##################################################################\n\n#Se inicializa la primera palabra\npalabra_encontrada=\"\"\n\n#Se inicializan las categorías con las palabras claves del texto. Se le añade la frecuencia, categoría, y la iteración.\nDataMaestra=mutate(DataMaestra,keyR1=\"\",keyR2=\"\",keyR3=\"\",keyR4=\"\",keyR5=\"\",\n                   Categoria_R=\"\",Frecuencia_R=0,j_R=0,PorcentajeR=0.0, Categoria_R1=\"\",Categoria_R2=\"\"\n)\n\n\n#Todavía no ha terminado, y la iteración es cero\nTerminar=FALSE\nj=0\n\nAux<-DataMaestra\n\n#Todo el corpus como un vector\nAbstractVector=as.vector(Aux$Titulo_Revista)\n\n#Vector vacío\nTotalKeyWords=vector(mode = \"character\",length=length(AbstractVector))\n\n######################################## Palabras Frecuentes        #########################################\n#names(DataMaestra)\n\n#Sacar las que no sirven (HECHO)\n\nfor(i in 1:nrow(DataMaestra)){\n  \n  #Cada abstract como un vector\n  NewAbstractVector=as.character(DataMaestra[i,\"Titulo_Revista\"])\n  \n  KeyWordsAbsi=Keyword_rev(NewAbstractVector)\n  rownamesFreq=rownames(KeyWordsAbsi)\n  DataMaestra[i,\"keyR1\"]=rownamesFreq[1]\n  DataMaestra[i,\"keyR2\"]=rownamesFreq[2]\n  DataMaestra[i,\"keyR3\"]=rownamesFreq[3]\n  DataMaestra[i,\"keyR4\"]=rownamesFreq[4]\n  DataMaestra[i,\"keyR5\"]=rownamesFreq[5]\n}\n\n\nView(DataMaestra)\n\n############################################################################################################\nAux<-DataMaestra\n\nj=0\n\n# while(!Terminar)\n# {\n  \n  #El conjunto de las palabras más frecuentes de cada abstract <-- \n  #Aquí la diferencia de haber sacado las más frecuentes del conjunto completo, \n  #esto es más representativo de lo que es importante en cada uno\n  prop<-1\n  TotalKeyWords=paste(Aux[,\"keyR1\"],Aux[,\"keyR2\"],Aux[,\"keyR3\"],Aux[,\"keyR4\"],Aux[,\"keyR5\"],sep=\" \")\n  TotalKeyWordsC<-Corpus(VectorSource(TotalKeyWords))\n  TotalKeyWordsC <-tm_map(TotalKeyWordsC,content_transformer(tolower))\n  toSpace <- content_transformer(function(x, pattern) { return (gsub(pattern, \" \", x))})\n  dtm <- DocumentTermMatrix(TotalKeyWordsC)\n  \n  #agrupar sumando por columnas\n  freq <- colSums(as.matrix(dtm))\n  \n  #el largo debe ser igual a total de términos\n  length(freq)-ncol(dtm)==0\n  \n  #ordenar por frecuencia (descendiente)\n  ord <- order(freq,decreasing=TRUE)\n  \n  #Enlistar los términos por frecuencia\n  FrecuenciaFinal=data.frame(freq[ord])\n  \n  palabra_encontrada=rownames(FrecuenciaFinal)\n  \n  \n  \n  \n  \n  #Colocar la etiqueta de categoria\n  for(i in 1:nrow(DataMaestra))\n  {\n    keys_revista=c(\"\",\"\")\n    m=1\n    for(h in 1:length(palabra_encontrada))\n    {\n      print(i)\n      if(existe_palabra(paste(DataMaestra[i,\"keyR1\"],DataMaestra[i,\"keyR2\"],DataMaestra[i,\"keyR3\"],DataMaestra[i,\"keyR4\"],DataMaestra[i,\"keyR5\"],sep=\" \"),palabra_encontrada[h]) )\n      {\n        if(m<3)\n        {\n          keys_revista[m]=palabra_encontrada[h]\n          m=m+1\n        }\n        else\n        {\n          break;\n          \n        }\n        \n        # \n        # DataMaestra[i,\"Categoria_R\"]=palabra_encontrada\n        # DataMaestra[i,\"Frecuencia_R\"]=FrecuenciaFinal[1,1]\n        # DataMaestra[i,\"j_R\"]=j\n        # DataMaestra[i,\"PorcentajeR\"]=FrecuenciaFinal[1,1]/nrow(DataMaestra)\n        # prop<-FrecuenciaFinal[1,1]/nrow(DataMaestra)\n      }\n    }\n    DataMaestra[i,\"Categoria_R1\"]=keys_revista[1]\n    DataMaestra[i,\"Categoria_R2\"]=keys_revista[2]    \n  }\n  # \n  # print(j)\n  # print(prop)\n  # print(palabra_encontrada)\n  # j=j+1\n  # Aux<-filter(DataMaestra,Categoria_R==\"\")\n  # print(nrow(Aux))\n  # if(nrow(Aux)==0 || prop<0.005)\n  # {\n  #   Terminar=TRUE\n  # }\n  \n# }\n\nDataMaestra$Categoria_R<-NULL\n\n\n\n#########################################################################\n#################### Guardar el dominio #################################\n#########################################################################\n\nDataMaestra%>%summary()\nDataMaestra$Disciplina<-as.factor(DataMaestra$Disciplina)\nDataMaestra$Categoria_1<-as.factor(DataMaestra$Categoria_1)\nDataMaestra$Cluster_15<-as.factor(DataMaestra$Cluster_15)\nDataMaestra$Cluster_8<-as.factor(DataMaestra$Cluster_8)\nDataMaestra$Cluster_20<-as.factor(DataMaestra$Cluster_20)\nDataMaestra$lda_10<-as.factor(DataMaestra$lda_10)\nDataMaestra$lda_30<-as.factor(DataMaestra$lda_30)\nDataMaestra$lda_45<-as.factor(DataMaestra$lda_45)\nDataMaestra$Titulo_Revista<-as.factor(DataMaestra$Titulo_Revista)\nDataMaestra$Categoria_R1<-as.factor(DataMaestra$Categoria_R1)\nDataMaestra$Categoria_R2<-as.factor(DataMaestra$Categoria_R2)\n\naddNoAnswer <- function(x){\n  if(is.factor(x)) return(factor(x, levels=c(levels(x), \"No Answer\")))\n  return(x)\n}\n\nDataMaestra <- as.data.frame(lapply(DataMaestra, addNoAnswer))\n\n\nl<-list()\nl[[\"Disciplina\"]]<-levels(DataMaestra$Disciplina)\nl[[\"Categoria_1\"]]<-levels(DataMaestra$Categoria_1)\nl[[\"Cluster_15\"]]<-levels(DataMaestra$Cluster_15)\nl[[\"Cluster_8\"]]<-levels(DataMaestra$Cluster_8)\nl[[\"Cluster_20\"]]<-levels(DataMaestra$Cluster_20)\nl[[\"lda_10\"]]<-levels(DataMaestra$lda_10)\nl[[\"lda_30\"]]<-levels(DataMaestra$lda_30)\nl[[\"lda_45\"]]<-levels(DataMaestra$lda_45)\nl[[\"Titulo_Revista\"]]<-levels(DataMaestra$Titulo_Revista)\nl[[\"Categoria_R1\"]]<-levels(as.factor(DataMaestra$Categoria_R1))\nl[[\"Categoria_R2\"]]<-levels(as.factor(DataMaestra$Categoria_R2))\n\n\n#########################################################################\n##################### Entrenamiento SVM #################################\n#########################################################################\n\nlibrary(dplyr)\nUniversoSupervisados<-filter(DataMaestra,!is.na(Disciplina));View(UniversoSupervisados)\n#install.packages(\"sampling\")\nlibrary(sampling)\n\nclasificados<-stratified(as.data.frame(UniversoSupervisados),7,.45)\n\n\n#names(clasificados)\n\nAbstract_Catalogados=mutate(clasificados, AbstractYRevista= paste(Abstract,keyR1,keyR2,keyR3,keyR4,keyR5,sep=\" \")) #paste(Abstract,Titulo_Revista,sep=\" \"))\n\nAbstract_Catalogados=filter(Abstract_Catalogados,Disciplina!=\"\")\n\nsource(\"Entrenamiento_Svm_1.R\")\n\nlevels(Abstract_Catalogados$Disciplina)<-l$Disciplina\nAbstract_Catalogados%>%summary()\n\nEntrenarSVMTexto(Abstract_Catalogados$Disciplina,Abstract_Catalogados$AbstractYRevista)\n\nmodelo<-readRDS(\"ModeloEntrenado.rds\")\n\n\n#Se saca el 55% restante para evaluar\nx <- rownames(UniversoSupervisados)\ny <- row.names(clasificados)\nres <- x[is.na(pmatch(x,y))]\n\nDataAEvaluar<-UniversoSupervisados[as.integer(res),]\n#names(DataAEvaluar)\n\nDataAEvaluar=mutate(DataAEvaluar, AbstractYRevista= paste(Abstract,keyR1,keyR2,keyR3,keyR4,keyR5,sep=\" \"))\n\nMATRIZ_CUERPO=modelo$MATRIZ\n\nPREDICCION_CUERPO <- crear_matriz(DataAEvaluar$AbstractYRevista\n                                  ,language='english'\n                                  ,removeNumbers=TRUE\n                                  ,stemWords=TRUE\n                                  ,toLower = TRUE\n                                  ,stripWhitespace = TRUE\n                                  ,removeStopwords = TRUE\n                                  ,originalMatrix=MATRIZ_CUERPO)\n\n\n\nlargo_prediccion_CUERPO=nrow(PREDICCION_CUERPO);\n\npredictionContainer_CUERPO<- create_container(PREDICCION_CUERPO, \n                                              labels=rep(0,largo_prediccion_CUERPO)\n                                              ,testSize=1:largo_prediccion_CUERPO, virgin=FALSE)\n\n\n\nmodelo_entrenado=modelo$MODELO\nscores <- classify_model(predictionContainer_CUERPO,modelo_entrenado)\n\nDataAEvaluar$Etiqueta<-scores$SVM_LABEL\nDataAEvaluar$Probabilidad<-scores$SVM_PROB\nView(DataAEvaluar)\n\ntable(DataAEvaluar$Disciplina,DataAEvaluar$Etiqueta)%>%as.data.frame()%>%cast(Var1~Var2)%>%View()\n\nlevels(DataAEvaluar$Etiqueta)<-levels(DataAEvaluar$Disciplina)\n\n##### Evaluacion ######\nCM_SVM<-confusionMatrix(DataAEvaluar$Disciplina,DataAEvaluar$Etiqueta)\nwrite.csv2(CM_SVM$table,\"CF_SVM.csv\")\nwrite.csv2(CM_SVM$overall,\"Accuracy_SVM.csv\")\nwrite.csv2(CM_SVM$byClass,\"CF_By_Class.csv\")\n\n\n\nsaveRDS(DataAEvaluar,\"SVMEvaluado.rds\")\n\n\nsvm_agrupado <- group_by(DataAEvaluar, Ano,Etiqueta)\nsvm_agrupado<-summarise(svm_agrupado, Total = n(),Probabilidad=mean(Probabilidad, na.rm = T) )\n\nView(svm_agrupado)\nwrite.csv(svm_agrupado,\"resultados_svm_agrupados_11_9_17.csv\")\n\nlibrary(ggplot2)\n\n\np <- ggplot(svm_agrupado, aes(Ano, log(Total)))\np + geom_point(aes(size=Probabilidad,color=factor(Etiqueta)))\n\n\narchivo<-paste(\"svm.png\")\npng(filename=archivo)\nlayout(matrix(c(1, 2), nrow=2), heights=c(1, 4))\npar(mar=rep(0, 4))\nplot.new()\ntext(x=0.5, y=0.5, paste(NivelesCategorias[i],\" svm_10_9_2017\"))\np <- ggplot(svm_agrupado, aes(Ano, log(Total)))\np + geom_point(aes(size=Probabilidad,color=factor(Etiqueta)))\n\ndev.off()\n\n\nNivelesCategorias=levels(as.factor(DataAEvaluar$Etiqueta))\n\nfor (i in 1:length(NivelesCategorias))\n{\n  #DataMaestra[,NivelesCategorias[i]]\n  Words<-filter(DataAEvaluar,Etiqueta==NivelesCategorias[i]) \n  print(i)\n  FrecuenciaFinal<-Keyword(Words$Abstract)\n  archivo<-paste(NivelesCategorias[i],\"_wordcloud_svm_11_10_2017.png\")\n  png(filename=archivo)\n  layout(matrix(c(1, 2), nrow=2), heights=c(1, 4))\n  par(mar=rep(0, 4))\n  plot.new()\n  text(x=0.5, y=0.5, paste(NivelesCategorias[i],\" Wordcloud\"))\n  \n  wordcloud(words = rownames(FrecuenciaFinal), freq = FrecuenciaFinal$freq.ord., min.freq = 1,\n            max.words=200, random.order=FALSE, rot.per=0.35, \n            colors=brewer.pal(8, \"Dark2\"),main=\"Title\")\n  dev.off()\n}\n\n\n\n\n########################## Logic Boost Sobre todo lo que queda ##############################\n\n\nnames(DataAEvaluar)\n\n\nDataAEvaluar$Disciplina<-as.factor(DataAEvaluar$Disciplina)\n\nDataAEvaluar%>%mutate(Categoria_R1=ifelse(\"\"==Categoria_R1,\"Sin Categoria\",Categoria_R1))->DataAEvaluar\n\nDataAEvaluar%>%mutate(Categoria_R2=ifelse(\"\"==Categoria_R2,\"Sin Categoria\",Categoria_R2))->DataAEvaluar\n\nView(DataAEvaluar)\nDataAEvaluar$Disciplina<-droplevels(DataAEvaluar$Disciplina)\n\nData_Para_logistica<-stratified(DataAEvaluar,7,.82)\n\n\nlevels(Data_Para_logistica$Disciplina)<-l$Disciplina\nlevels(Data_Para_logistica$Categoria_1)<-l$Categoria_1\nlevels(Data_Para_logistica$Categoria_R1)<-l$Categoria_R1\nlevels(Data_Para_logistica$Categoria_R2)<-l$Categoria_R2\nlevels(Data_Para_logistica$Cluster_15)<-l$Cluster_15\nlevels(Data_Para_logistica$lda_30)<-l$lda_30\nlevels(Data_Para_logistica$Etiqueta)<-l$Disciplina\n\nView(Data_Para_logistica)\n\ndroplevels(Data_Para_logistica)->Data_Para_logistica\n\nglm<-train(Disciplina ~ Categoria_R1+Categoria_R2+ Categoria_1+Cluster_15+lda_30+Etiqueta, data = Data_Para_logistica, \n      method = \"LogitBoost\")\n\n\nx <- rownames(DataAEvaluar)\ny <- row.names(Data_Para_logistica)\nres <- x[is.na(pmatch(x,y))]\n\nEvaluacionBosque<-DataAEvaluar[as.integer(res),]\n\n#levels(as.factor(EvaluacionBosque$Categoria_R1))%in%levels(as.factor(Data_Para_logistica$Categoria_R1))\n\nEvaluacionBosque%>%mutate(Categoria_R1=ifelse(Categoria_R1%in%levels(as.factor(Data_Para_logistica$Categoria_R1)),Categoria_R1,\"Sin Categoria\"))->EvaluacionBosque\n\nEvaluacionBosque%>%mutate(Categoria_R2=ifelse(Categoria_R2%in%levels(as.factor(Data_Para_logistica$Categoria_R2)),Categoria_R2,\"Sin Categoria\"))->EvaluacionBosque\n\n#levels(as.factor(Aux$Categoria_R1))%in%levels(as.factor(Data_Para_logistica$Categoria_R1))\n\n\npredict(glm,as.data.frame(EvaluacionBosque))->p\n\ntable(EvaluacionBosque$Disciplina,p)\n\nlevels(p)<-levels(as.factor(c(levels(p),levels(EvaluacionBosque$Disciplina))))\nlevels(EvaluacionBosque$Disciplina)<-levels(p)\n\nCMlb<-confusionMatrix(EvaluacionBosque$Disciplina,p)\n\n\n\n##### Evaluacion ######\nwrite.csv2(CMlb$table,\"CM_lb.csv\")\nwrite.csv2(CMlb$overall,\"Accuracy_lb.csv\")\nwrite.csv2(CMlb$byClass,\"CM_By_Class_lb.csv\")\n\n\n\n########################## Bosque Sobre todo lo que queda ##############################\n\n\nRForest<-train(Disciplina ~ Categoria_R1+Categoria_R2+ Categoria_1+Cluster_15+lda_30+Etiqueta, data = Data_Para_logistica, \n           method = \"ranger\", importance=\"impurity\")\n\n#Escoger modelos\n#https://topepo.github.io/caret/available-models.html\n\nx <- rownames(DataAEvaluar)\ny <- row.names(Data_Para_logistica)\nres <- x[is.na(pmatch(x,y))]\n\nEvaluacionBosque<-DataAEvaluar[as.integer(res),]\n\nEvaluacionBosque%>%mutate(Categoria_R1=ifelse(Categoria_R1%in%levels(as.factor(Data_Para_logistica$Categoria_R1)),Categoria_R1,\"Sin Categoria\"))->EvaluacionBosque\nEvaluacionBosque%>%mutate(Categoria_R2=ifelse(Categoria_R2%in%levels(as.factor(Data_Para_logistica$Categoria_R2)),Categoria_R2,\"Sin Categoria\"))->EvaluacionBosque\npredict(glm,as.data.frame(EvaluacionBosque))->p\ntable(EvaluacionBosque$Disciplina,p)\n\nlevels(p)<-levels(as.factor(c(levels(p),levels(EvaluacionBosque$Disciplina))))\nlevels(EvaluacionBosque$Disciplina)<-levels(p)\nCMbosque<-confusionMatrix(EvaluacionBosque$Disciplina,p)\n\n##### Evaluacion ######\nwrite.csv2(CMbosque$table,\"CM_Bosque.csv\")\nwrite.csv2(CMbosque$overall,\"Accuracy_Bosque.csv\")\nwrite.csv2(CMbosque$byClass,\"CM_By_Class_Bosque.csv\")\n\n\n#Importancia de las variables con el indice de Gini\n#install.packages(\"randomForest\")\nranger::importance(RForest$finalModel)%>%as.data.frame()%>%View()\n\n\n\n####################################################################################################\n\nUniversoSupervisados$Disciplina<-as.factor(UniversoSupervisados$Disciplina)\n\nUniversoSupervisados%>%mutate(Categoria_1=ifelse(is.na(Categoria_1),\"Sin Categoria\",Categoria_1))->DataAEvaluar\nUniversoSupervisados$Categoria_1<-as.factor(UniversoSupervisados$Categoria_1)\nUniversoSupervisados$Titulo_Revista<-as.factor(UniversoSupervisados$Titulo_Revista)\n\nUniversoSupervisados$Cluster_10<-as.factor(UniversoSupervisados$Cluster_10)\nUniversoSupervisados$lda_30<-as.factor(UniversoSupervisados$lda_30)\n\nstr(UniversoSupervisados)\n\nEvaluacion90<-stratified(as.data.frame(UniversoSupervisados),7,.9)\nView(clasificados);View(UniversoSupervisados)\n\n\nx <- rownames(UniversoSupervisados)\ny <- row.names(Evaluacion90)\nres <- x[is.na(pmatch(x,y))]\n\nEvaluacion10<-UniversoSupervisados[as.integer(res),]\n\n\nglm<-train(Disciplina ~ Titulo_Revista+ Categoria_1+Cluster_10+lda_30, data = Evaluacion90, \n           method = \"LogitBoost\")\n\n\n\npredict(glm,as.data.frame(Evaluacion10))->p\n\nCMlb<-confusionMatrix(Evaluacion10$Disciplina,p)\n\nCMlb$overall\n\n\n##########################################De aquí en adelante no cacho qué es. Me tinca que son sobras del SVM.\n\n#names(clasificados)\n\nAbstract_Catalogados=mutate(Evaluacion90, AbstractYRevista= paste(Abstract,Titulo_Revista,sep=\" \"))\n\nAbstract_Catalogados=filter(Abstract_Catalogados,Disciplina!=\"\")\n\nsource(\"Entrenamiento_Svm_1.R\")\n\nEntrenarSVMTexto(Abstract_Catalogados$Disciplina,Abstract_Catalogados$AbstractYRevista)\n\nmodelo<-readRDS(\"ModeloEntrenado.rds\")\n\nDataAEvaluar<-Evaluacion10\n#names(DataAEvaluar)\n\nDataAEvaluar=mutate(DataAEvaluar, AbstractYRevista= paste(Abstract,Titulo_Revista,sep=\" \"))\n\nMATRIZ_CUERPO=modelo$MATRIZ\n\nPREDICCION_CUERPO <- crear_matriz(DataAEvaluar$AbstractYRevista\n                                  ,language='english'\n                                  ,removeNumbers=TRUE\n                                  ,stemWords=TRUE\n                                  ,toLower = TRUE\n                                  ,stripWhitespace = TRUE\n                                  ,removeStopwords = TRUE\n                                  ,originalMatrix=MATRIZ_CUERPO)\n\n\n\nlargo_prediccion_CUERPO=nrow(PREDICCION_CUERPO);\n\npredictionContainer_CUERPO<- create_container(PREDICCION_CUERPO, \n                                              labels=rep(0,largo_prediccion_CUERPO)\n                                              ,testSize=1:largo_prediccion_CUERPO, virgin=FALSE)\n\n\n\nmodelo_entrenado=modelo$MODELO\nscores <- classify_model(predictionContainer_CUERPO,modelo_entrenado)\n\nDataAEvaluar$Etiqueta<-scores$SVM_LABEL\nDataAEvaluar$Probabilidad<-scores$SVM_PROB\nView(DataAEvaluar)\n\ntable(DataAEvaluar$Disciplina,DataAEvaluar$Etiqueta)%>%as.data.frame()%>%cast(Var1~Var2)\n\nconfusionMatrix(DataAEvaluar$Disciplina,DataAEvaluar$Etiqueta)\n\n\n\n\n\n",
    "created" : 1506793503444.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "460767269",
    "id" : "6813E47B",
    "lastKnownWriteTime" : 1515350108,
    "last_content_update" : 1515350108684,
    "path" : "~/Tesis/categoría_1 080717.R",
    "project_path" : "categoría_1 080717.R",
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}